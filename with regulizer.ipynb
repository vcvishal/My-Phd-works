{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './efs/training/',  # This is the source directory for training images\n",
    "        target_size=(512, 512),  # All images will be resized to 200 x 200\n",
    "        batch_size=batch_size,\n",
    "        # Specify the classes explicitly\n",
    "        classes = ['40_to_49','above50','below40'],\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    './efs/validation/',\n",
    "    target_size=(512,512),\n",
    "    #rescale=1. / 255,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(512, 512, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a dense layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 128 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # 5 output neurons for 5 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "total_sample=train_generator.n\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch=int(total_sample/batch_size),\n",
    "        validation_data=validation_generator,\n",
    "        epochs=n_epochs,\n",
    "        verbose=1)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.utils as image\n",
    "test_image = image.load_img('1.jpg', target_size = (512,512))\n",
    "#test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "print(result.shape)\n",
    "if result[0][1] == 1:\n",
    "    print(\"40_to_49\")\n",
    "elif result[0][0] == 1:\n",
    "    print(\"above50\")\n",
    "elif result[0][2] == 1:\n",
    "    print(\"below40\")\n",
    "\n",
    "#scoreSeg = model.evaluate_generator(validation_generator, 100)\n",
    "#print(scoreSeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSeg = model.evaluate_generator(validation_generator, 100)\n",
    "print(scoreSeg)\n",
    "#model.save_weights(\"best till today 95% regularizer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Get the filenames from the generator\n",
    "fnames = validation_generator.filenames\n",
    "\n",
    "# Get the ground truth from generator\n",
    "ground_truth = validation_generator.classes\n",
    "\n",
    "# Get the label to class mapping from the generator\n",
    "label2index = validation_generator.class_indices\n",
    "\n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())\n",
    "\n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n",
    "predicted_classes = np.argmax(predictions,axis=1)\n",
    "\n",
    "errors = np.where(predicted_classes == ground_truth)[0]\n",
    "print(\"No of pass = {}/{}\".format(len(errors),validation_generator.samples))\n",
    "\n",
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n",
    "\n",
    "# Show the errors\n",
    "for i in range(len(errors)):\n",
    "    pred_class = np.argmax(predictions[errors[i]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "    \n",
    "    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "        fnames[errors[i]].split('\\\\')[0],\n",
    "        pred_label,\n",
    "        predictions[errors[i]][pred_class])\n",
    "    \n",
    "    original = load_img('{}\\{}'.format('./efs/validation/',fnames[errors[i]]))\n",
    "    plt.figure(figsize=[7,7])\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.imshow(original)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "test_steps_per_epoch = numpy.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(validation_generator, steps=test_steps_per_epoch)\n",
    "# Get most likely class\n",
    "predicted_classes = numpy.argmax(predictions, axis=-1)\n",
    "print(predicted_classes)\n",
    "\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys()) \n",
    "\n",
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report) \n",
    "print(predicted_classes)\n",
    "print(true_classes)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=\"viridis\")\n",
    "    plt.show()\n",
    "    print(conf_matx)\n",
    "print(draw_confusion_matrix(true_classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pycm import *\n",
    "y_actu=true_classes\n",
    "y_pred=predicted_classes\n",
    "\n",
    "cm = ConfusionMatrix(actual_vector=y_actu, predict_vector=y_pred)\n",
    "\n",
    "cm.classes\n",
    "cm.table\n",
    "print(cm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "\n",
    "# ResNet50 model\n",
    "resnet_50 = ResNet50(include_top=False, weights='imagenet', input_shape=(512,512,3))\n",
    "for layer in resnet_50.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# build the entire model\n",
    "x = resnet_50.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x) \n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='relu')(x) \n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(128, activation='relu')(x) \n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x) \n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs = resnet_50.input, outputs = predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
